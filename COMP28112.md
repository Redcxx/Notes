## Definition

### System

A complex whole; connected parts; a organized assembly of resources and organized by interaction / independent to accomplish a set of specific functions.

### Distributed System

An network of hardware / software running independently, communicate and coordinate their actions only by passing messages.

A collection of computers which appear to its user as a whole.

### Consequences

#### Concurrency

Components can do their own work and share resources only when necessary, The capacity of system handling more resources can be increased by adding more components. The coordination of the components is an important topic // TODO

- Non-deterministic
- Race condition
- Synchronization
- Deadlock

#### No Global Clock / State

Components need to coordinate their action, this is often depend on the time but the only way components can exchange messages is by passing message. This result in limited accuracy. // TODO

- Coordination is done by message exchange.
- No single global notion of correct time.
- No component knows the current global state of the system.

#### Independent Failures

All computer systems can fail, in distributed computing, components fail individually and other components is responsible for handling such error and continue running.

- Network failure can isolate computers that still running.
- Component failure is not immediately known.

#### Linked by a network

// TODO

### Examples

- #### Web Search

  There are over 1.74billion websites on the internet (Jan 2020), searching through such massive index requires many technology.

  - A very large number of networks of computers located at data centers around the world.
  - The associated distributed data (file) system heavily optimized for large data search.
  - The associated storage system which required fast access to large dataset.
  - A lock service that offers distributed locking and agreements.
  - A efficient computational model for very large parallel and distributed computing.

- #### Massive Multiple-player Online Games (MMOGs)

  As of Sep 2019, League of Legends has over 8 million concurrent players at peak. A geographically distributed servers is needed to ensure low response time for players to have a good experience

- #### DNS

- #### Banking / Airline Reservation System

- #### Peer-to-peer networks

- #### Apps (whatsapp, facebook, skype...)

##  8 Fallacies of distributed computing.

### The network is reliable

Someone went to cut the fibre wire before. We cannot assume network is always reliable, we need to care about error handling, else you may wait infinite amount of time waiting for a failed computer to response and permanently consuming computer memory or other resources.

In term of hardware, we have to trade between building redundancy (//TODO, what redundancy) and risk of failures. In term of software, we need handling such as reorder / retry / acknowledge message exchange, verify message integrity and so on.

### The network is secure

Big companies lost tons of records in the past few years... We cannot assume network is secure and some form of protection is needed.

We need to build security into our application from day 1. We also give people with different privilege so they may not have access to information they wanted.

### Latency is zero

This is time taken to transport the data. The speed of light pose a limit on transport. Even if you are deploying your application on a LAN, it is better to make as little calls as possible.

There is latency in transport, and it comes with pack loss. If you assume there is unbounded traffic then you may waste bandwidth and cause lots of packet loss.

### Bandwidth is infinite

With more money you can have more bandwidth, but you do not have infinite money. Assuming bandwidth is infinite can result in bottlenecks. It is growing continuously, but so as the data. We have to use compression if we want to send large amount of data. We also need to stimulate the production environment to estimate the amount of bandwidth needed.

### Topology does not change

If you write scripts assume there is only 2 servers and you add / remove servers in the future, boom, your application is messed up. It can also result in changes of latency and bandwidth which cause similar problems. This means that we cannot rely on specific endpoint or the route we took. For example, we should use DNS names instead of IP addresses.

### There is one administrator

The senders must be aware that there are multiple administrators and they can have conflicting policies in order to complete their desired path. They also comes with different level of expertise thus hard to determine whether is your / their fault.

### Transport cost is zero

Transport requires money and are non-negligible,  it needs to be noted in budgets to avoid vast shortfalls. The cost of travelling from the application level to transport level is not free, we also need to serialize the data and set up the transportation. For example we need to lease the bandwidth.

### Network is homogenous

This assume that computers in the network uses similar configurations and protocols which can cause similar problems as the first three fallacies: *network is secure*, *latency is zero* and *bandwidth is infinite*. For example, even in the same LAN, computers can run with different OS. This implies that computers have to follows some kind of standard protocol, such as the HTML for transferring data.

# Miscellaneous

### Goals

Heterogeneity, openness, security, scalability, failure handling, concurrency, transparency

### Heartbleed

Heartbleed is a security bug in the OpenSSL cryptography library, which is a widely used implementation of the ***Transport Layer Security*** (**TLS**). It is introduced in the software in 2012, publicly fixed and disclosed in May 2014. The bug is caused by missing bounds check in the implementation in the TLS ***heartbeat*** *(thus the name heartbleed)* extension and belong to kind of buffer-overflow attack.

### Why distributed computing

People are distributed but works together; hardware needs to be close to people (who are distributed); Information need to be shared; Hardware can be shared and increase computational power.

### Distributed is not always good

Distributed computation can split the computation burden, but it comes with cost. Firstly, not all tasks can be parallel, there can be depedency in the code. Secondly, maintaining threads / processes / computers are not free, we will reach a pleatu at some point where adding more components does not improve performance.



### Parallelizing application

- Identify instructions can be execute in parallel.
- Identify multiple data can be process in parallel.

## Questions

1. You are retrieving a 100mb file from server, assuming bandwidth 100 mb/sec and latency is 1sec, do you make 1 request to retrieve the file or 10 requests to make retrieve 10mb each time? Which option is better? <one request is better> 

If the latency of the network link between the client and the server is 1sec and the available bandwidth is 100MB/sec which option would be faster? What if the latency is 1msec? What do you conclude? 
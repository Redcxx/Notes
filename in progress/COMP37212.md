

# COMP 37212

# Lectures

## Lecture 1 Binary Images

We can think a greyscale image as a function, $I$, that given $(x,y)$, output the intensity at that position, and the digital image, is the discrete (sampled and quantized) version of this function.

<img src="COMP37212.assets/image-20210226145249488.png" alt="image-20210226145249488" style="zoom:50%;" />

Sometimes we do not care about the spatial information, just the distribution, so we have histogram:

<img src="COMP37212.assets/image-20210226145412747.png" alt="image-20210226145412747" style="zoom: 33%;" />

The number of pixels determine the spatial resolution, a 512x512 is good enough most of time.

<img src="COMP37212.assets/image-20210226150130396.png" alt="image-20210226150130396" style="zoom:33%;" />

The number of grey determine the grey-level resolution (i.e. how many colours you can represents):

<img src="COMP37212.assets/image-20210226151156311.png" alt="image-20210226151156311" style="zoom: 33%;" />

Image transformation as function:

<img src="COMP37212.assets/image-20210226151449432.png" alt="image-20210226151449432" style="zoom:33%;" />

Subsampling (downscale image) is also useful in some scenarios, e.g. speed up algorithms. Instead of down scaling directly, it is better to do local average pooling, this preserve the overall information.

## Lecture 2 Segmentation

Threshold can be used (histogram often used in the algorithm), but it does not work well for images like:

<img src="COMP37212.assets/image-20210226174103108.png" alt="image-20210226174103108" style="zoom:33%;" />

use adaptive thresholding would be better:

<img src="COMP37212.assets/image-20210226174145690.png" alt="image-20210226174145690" style="zoom:33%;" />

## Lecture 3 Neighbourhood Processing

Uses kernel

- **Rank filtering**

  median can remove the noise better than average. Average will blur the edge, but median preserve the edge.
  <img src="COMP37212.assets/image-20210227120009897.png" alt="image-20210227120009897" style="zoom: 33%;" />
  <img src="COMP37212.assets/image-20210227120101442.png" alt="image-20210227120101442" style="zoom: 33%;" />

- **Convolution**
   <img src="COMP37212.assets/image-20210227133837450.png" alt="image-20210227133837450" style="zoom:33%;" />
  <img src="COMP37212.assets/image-20210227133959362.png" alt="image-20210227133959362" style="zoom:33%;" />

## Lecture 4 Edges and Convolution

edge detection should have:

- good detection
- good localization (detected edge should be close to true edges)
- single response (minimize number of local maxima)

<img src="COMP37212.assets/image-20210315173447205.png" alt="image-20210315173447205" style="zoom:33%;" />



Edges are area in the images where intensity changes rapidly.

<img src="COMP37212.assets/image-20210315141129823.png" alt="image-20210315141129823" style="zoom:33%;" />

<img src="COMP37212.assets/image-20210315141157524.png" alt="image-20210315141157524" style="zoom:33%;" />

 <img src="COMP37212.assets/image-20210315141743999.png" alt="image-20210315141743999" style="zoom:33%;" />

But it works badly when there is noise:

<img src="COMP37212.assets/image-20210315143049835.png" alt="image-20210315143049835" style="zoom:33%;" />

We can first smooth the image first before doing edge detection:

<img src="COMP37212.assets/image-20210315143120545.png" alt="image-20210315143120545" style="zoom: 50%;" /> 

<img src="COMP37212.assets/image-20210315143646513.png" alt="image-20210315143646513" style="zoom:33%;" />

Note that we can perform differentiation with convolution, with kernel like (1,-1):

<img src="COMP37212.assets/image-20210315150006677.png" alt="image-20210315150006677" style="zoom:33%;" />

Lets see some popular kernels:

<img src="COMP37212.assets/image-20210315150323838.png" alt="image-20210315150323838" style="zoom:33%;" />

Prewitt smooth along the edge and detect the opposite side's edges.

<img src="COMP37212.assets/image-20210315150513702.png" alt="image-20210315150513702" style="zoom:33%;" />

<img src="COMP37212.assets/image-20210326170946811.png" alt="image-20210326170946811" style="zoom:33%;" />

Sober kernel uses weighted smoothing instead.

<img src="COMP37212.assets/image-20210315150738167.png" alt="image-20210315150738167" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210315150904851.png" alt="image-20210315150904851" style="zoom:33%;" />

Gradient is an important concept.

<img src="COMP37212.assets/image-20210326170855635.png" alt="image-20210326170855635" style="zoom:33%;" />

convolution can be made faster by applying a trick: decomposing them into two kernels:

<img src="COMP37212.assets/image-20210315151852330.png" alt="image-20210315151852330" style="zoom:33%;" />

one of the reason why gaussian smoothing is used so often, is because it is also decomposable:

<img src="COMP37212.assets/image-20210315160922229.png" alt="image-20210315160922229" style="zoom:33%;" />

Another thing is that gaussian kernel has nice properties, like anti-aliasing (before subsample an image, loss little fine details but capture the overall structure).

- 2-dimensional: <img src="COMP37212.assets/image-20210315163024314.png" alt="image-20210315163024314" style="zoom: 25%;" />ï¼Œ <img src="COMP37212.assets/image-20210326172637383.png" alt="image-20210326172637383" style="zoom: 25%;" />
- 3-dimensional:<img src="COMP37212.assets/image-20210315163107272.png" alt="image-20210315163107272" style="zoom: 25%;" />

The sigma parameter controls the spread of the gaussian smoothing.

<img src="COMP37212.assets/image-20210315163231003.png" alt="image-20210315163231003" style="zoom:33%;" />

since we have the formula, we can calculate the derivative of gaussian, it is often just called the canny operator.

<img src="COMP37212.assets/image-20210315165843054.png" alt="image-20210315165843054" style="zoom:33%;" />

The derivative of the gaussian function allow us to select scales of the sigma for edge detection.

 <img src="COMP37212.assets/image-20210315171206263.png" alt="image-20210315171206263" style="zoom: 33%;" />

This is the first step of the canny edge detector.  Remember that we can also find edge by finding zero-crossing at 2nd derivative. So we also have second derivative kernels like the Laplacian:

<img src="COMP37212.assets/image-20210315172634881.png" alt="image-20210315172634881" style="zoom:33%;" />

We lose information about the edge direction information since it is isotropic, and sometimes it can be useful to know. Another problem is that the response is not directly relate to the strength of the edge.

Instead of first applying the smoothing method, like gaussian, we can apply the second derivative kernel on the gaussian kernel, then we can directly use this applied kernel to detect edges, this is often call Laplacian of Gaussian (LoG).

<img src="COMP37212.assets/image-20210327103145077.png" alt="image-20210327103145077" style="zoom:33%;" />

sigma here again gives the scale selection.

2D filters:

<img src="COMP37212.assets/image-20210327103306644.png" alt="image-20210327103306644" style="zoom:33%;" />

<img src="COMP37212.assets/image-20210327103320059.png" alt="image-20210327103320059" style="zoom:33%;" />



## Lecture 5 Segmentation and Grouping

### Segmentation and Grouping

The goal of segmentation and grouping is to gather features that belong together.

<img src="COMP37212.assets/image-20210327104632337.png" alt="image-20210327104632337" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327104944439.png" alt="image-20210327104944439" style="zoom:33%;" />

The Gestalt School says that

- grouping is key to visual perception
- elements in a collection can have properties that result from relationship

<img src="COMP37212.assets/image-20210327105316164.png" alt="image-20210327105316164" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327105454907.png" alt="image-20210327105454907" style="zoom:33%;" />

Psychologist identified series of factors that predispose set of elements to be grouped by human visual system. But despite this inspiring result, the segmentation task is still hard and largely depend on the problem you trying to solve (what considered to be interesting separation).

There are two approaches:

- top-down: pixels belong together because they are from the same object.
- bottom-up: pixels belong together because they look similar.

<img src="COMP37212.assets/image-20210327110125848.png" alt="image-20210327110125848" style="zoom:33%;" />

But the ground truth may not be consistent:

<img src="COMP37212.assets/image-20210327111357518.png" alt="image-20210327111357518" style="zoom:33%;" />

the final ground truth is computed like a weighting of how consistent they are.

<img src="COMP37212.assets/image-20210327111621210.png" alt="image-20210327111621210" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327111714182.png" alt="image-20210327111714182" style="zoom:33%;" />

###  Segmentation as Clustering

segmentation is similar to clustering, except that clustering often does not care about the spatial representation unlike image that are grouped nicely.

Often we get noisy image that does not allow us to separate, and we have to determine the intensity as a group. It is an unsupervised learning task that group the pixels. 

<img src="COMP37212.assets/image-20210327112146467.png" alt="image-20210327112146467" style="zoom:33%;" />

Our goal is to find the centers such that when pixels are calculated towards the closest center, they are classified into the correct group. 

<img src="COMP37212.assets/image-20210327112622183.png" alt="image-20210327112622183" style="zoom:33%;" />

Kmeans: always converge to some solution, can be local minimum.

<img src="COMP37212.assets/image-20210327153135746.png" alt="image-20210327153135746" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327153212915.png" alt="image-20210327153212915" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327153317104.png" alt="image-20210327153317104" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327153728495.png" alt="image-20210327153728495" style="zoom:33%;" />



### Probabilistic

<img src="COMP37212.assets/image-20210327155235258.png" alt="image-20210327155235258" style="zoom:33%;" />

 

<img src="COMP37212.assets/image-20210327160159514.png" alt="image-20210327160159514" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327160435147.png" alt="image-20210327160435147" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327160703908.png" alt="image-20210327160703908" style="zoom:33%;" />

idea

<img src="COMP37212.assets/image-20210327161652445.png" alt="image-20210327161652445" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327162053131.png" alt="image-20210327162053131" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327164033918.png" alt="image-20210327164033918" style="zoom:33%;" />

 

<img src="COMP37212.assets/image-20210327164405238.png" alt="image-20210327164405238" style="zoom:33%;" />



<img src="COMP37212.assets/image-20210327165433159.png" alt="image-20210327165433159" style="zoom:33%;" />



 <img src="COMP37212.assets/image-20210327165851270.png" alt="image-20210327165851270" style="zoom:33%;" />



### Mean Shift



<img src="COMP37212.assets/image-20210327183804462.png" alt="image-20210327183804462" style="zoom:33%;" />



 <img src="COMP37212.assets/image-20210327184739433.png" alt="image-20210327184739433" style="zoom:33%;" />




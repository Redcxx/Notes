# Glossary

- Optimization: find the minimum by

  - Systematically choose the value of the function input from an allowed set.

  - Compute the value of the function using the chosen value.




# Introduction

> #### Can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes?

Machine learning is about making the computer learn how to do a certain task without explicitly coding it.



## Overview

### Machine Learning Pipeline

- Model Construction

  - Prepare data in a proper format

  - Characterize the task by a parametric model

    - Model the target
      - linear model
      - linear basis function
      - kernel methods
      - neural networks
    - Model the posterior
      - naive Bayes
      - logistic regression
      - Bayesian regression

  - Construct objective/loss function

    - sum-of-squared error

    - mean squared error
    - (log) likelihood
    - cross-entropy
    - hinge loss

- Training

  - optimize the loss function
    - zero gradient
    - gradient descent
    - stochastic gradient descent
    - mini-batch gradient descent

- Evaluate

### Learning

> #### A machine learns with respect to a task T, performance metric P and experience P; if the system reliably improves its performance on metric P at task T following experience P.

- Supervised Learning --- sample input and output, relationship

  - Classification --- categorise (discrete)

    - Binary --- one of two classes

    - Multi-label --- some of many classes

    - Multi-class --- one of many classes

    - Structured --- data into a structure (break sentence to semantic word)
    - Linear Regression  --- estimate a pattern (continuous)
    - Ordinal Regression --- between classification and linear regression (ordinal)

- Unsupervised Learning --- no teacher, hidden structure

  - Clustering --- grouping

  - Generative Modelling --- about the distribution
  - Unsupervised Representation Learning --- remove noise

- Reinforcement Learning --- reward and punishment

#### Typical Tasks

- Classification: assign to known classes
- Ranking: Sort from best to worst
- Seriation: Arrange by similarity
- Clustering: Group by similarity
- Regression: Estimate relationships
- Planning: Automatically create & improve policy
- Matching: Find the most similar

# Algorithms

## K Nearest Neighbour (KNN)

This algorithm belongs to the family of **Instance-based learning** --- produce output based on similarity/distance between the query and the nearest neighbor(s) in training set.

There are two types of KNN algorithms, **classification**, and **regression**. There is no explicit training but there is a hyperparameter --- the number of neighbors K used to calculate the result.

The number of K chosen can have significant on the result. If the K is too small, it may model noise; if the K is too big, it will include too much sample from other classes --- class that has more training samples wins. Note that K should not be an even number to lower the possibility of duplicate

Insufficient information if the training set is too small, expensive to calculate if too big, overfitting if the training set is noisy.



# Measuring Performance

## Accuracy & Error Rate

- accuracy: $\frac{corrects}{samples}$
- error rate: $\frac{wrongs}{samples}$

## Classification

### Confusion Matrix

Accuracy and error rate are not enough for assessing the performance, they show the overall result but do not reflect on the data and behaviors. Thus we use a confusion matrix that can show the performance of each class, it also enables us to calculate some stats.

- **sensitivity**, **recall**, hit rate, or true positive rate (TPR): 数据正方正确率

  - $\frac{TP}{TP+FN}$

- **specificity**, selectivity or true negative rate (TNR): 数据反方正确率

  - $\frac{TN}{TN+FP}$

  - 1- specificity or false positive rate (FPR)
    - $1-\frac{TN}{TN+FP}=\frac{FP}{TN+FP}$

- **precision** or positive predictive value (PPV): 模型正方正确率

  - $\frac{TP}{TP+FP}$

- negative predictive value (NPV): 模型反方正确率

  - $\frac{TN}{TN+FN}$

- **F1 score** (harmonic mean of precision and sensitivity): 对于模型和数据的正确的正方的平均值

  - $\frac{2TP}{2TP+FP+FN}$

- ROC Analysis is sensitivity against 1-specificity as the ***decision threshold*** varies. 即对于数据而言，随着反方的错误率（x轴）提升，正方正确率的变化（y轴）；对于决定边界来说即随着把全部归于反方到逐渐全部归于正方，正方正确率的变化。We can calculate the area under the curve, the higher the better.

   ![roc-image](https://i.ibb.co/wJMhF8z/screenshot-online-manchester-ac-uk-2020-01-17-15-19-43.png)

## Regression

Assume ***n*** samples, each sample has ***m*** outputs.

- Root Mean Squared Error (RMSE)

$$RMSE = \sqrt{\frac{1}{nm}\sum_{i=1}^{n}{\sum_{j=1}^{m}{(\hat{y}_{ij}-y_{ij})^2}}}$$

- Mean Absolute Error (MAE)

$$MAE = \frac{1}{nm}\sum_{i=1}^{n}{\sum_{j=1}^{m}{|\hat{y}_{ij}-y_{ij}|}}$$

- Mean Absolute Percentage Error (MAPE)

$$MAPE = \frac{1}{nm}\sum_{i=1}^{n}{\sum_{j=1}^{m}{\frac{|y_{ij}-\hat{y}_{ij}|}{|y_{ij}|}}}$$

- Coefficient of determination

![cod-image](https://i.ibb.co/dkwGYCb/screenshot-online-manchester-ac-uk-2020-01-17-15-39-57.png)

## Sample Error & True Error

Sample error refers to error compute by performance metrics using a set of the training sample. The true error refers to the probability of a randomly selected sample is misclassified in classification and the expectation of error in the regression case. We would like to know the true error, not just the sample error, we can always calculate the sample error; from the sample error, we can try to approximate the true error, but there is bias and variance issue. 

Bias because the training sample often gives an optimistically biased estimate of the unseen samples, luckily, by choosing test samples independently from the training samples we can obtain an unbiased estimate. 

Variance refers to the accuracy of the independently chosen test samples can still be a bad estimator depends on the samples, a smaller amount of samples leads to greater variance.

- Bias Error: $(y-E[y])^2$
- Variance Error: $E[(f-E[f])^2]$

A complex model can leads to overfitting --- too sensitive to small fluctuations in the training set. On the other hand, an overly simple model can lead to under-fitting

Now, we can answer the question of how to estimate the true error from sample error? We can use a confidence interval, that is, how confident are we that true error lays in a given range of the sample error?

<img src="https://i.ibb.co/ygT1zyv/screenshot-online-manchester-ac-uk-2020-01-17-17-12-51.png" alt="z-test-image-1" style="zoom:96.3%;" />

<img src="https://i.ibb.co/BZdSWs3/screenshot-online-manchester-ac-uk-2020-01-17-17-14-56.png" alt="z-test-image-2" style="zoom: 80%;" />

<img src="https://i.ibb.co/d5vDKwj/screenshot-online-manchester-ac-uk-2020-01-17-17-18-17.png" alt="z-test-image-3" style="zoom:81%;" />

**Z-test** is a way to calculate the probability of one classifier has higher true error than another given the sample error of the two. Note that z-test works even if two sample errors are tested on different sets of data but require it to contain over 30 samples.

# Data Separation

- **Holdout**

Separate the data into two groups. May get a bad spilt and there may not have enough data for testing.

- **Random Sampling**

Split the data into K sets of same size. For each set randomly select fixed number of samples for testing and use others for training then calculate the average error.

- **K-Fold**

Divide the entire dataset into K partition. For each partition, use it for testing and others for training and calculate the average error.

- **Leave-One-Out (N-Fold)**

For every sample, use it for testing and others for training then calculate the average error.

- **Bootstrap**

For K times, randomly select M number of samples (allow repeat) for training, select some samples from the rest for testing and calculate the average error.

# Formulas

## KNN

- Distance: $\text{Euclidean}^{t=2}$ and  $\text{Minkowski}^{t=1}$.
- Similarity: cos: $s_{cos}(p,q)=\frac{pq}{||p||_{2}||q||_{2}}$.

Converting distance to cosine: $d(p,q)=1 - s_{cos}(p,q)$.

# Model Construction

## Concepts

Three Approaches

- ***Find the mapping function*** from input to output $\hat{y} = f(x)$
- ***Model the posterio***r $p(f|x)$ and choose class with the highest probability, for regression is the conditional mean of $f$, $\hat{y} = E_f[f|x]$.
- ***Use Bayes' theorem*** to update the likelihood and prior: $p(x|y) \text{ and } p(y)$.

Two Model Types

- Multiple inputs, **single** output.
- Multiple inputs, **multiple** outputs.

## Basic Methods (Approach I)

### Linear Model (linear)

$\hat{y} = w_1x_0 + w_0$.

By solving the equation (setting $\hat{y}$ to some value) you get a line that separate the data points into two groups. The line is also called a ***decision boundary***. If you solve it by setting $\hat{y}$ to $0$, it is called a ***hyperplane***.

### Linear Basis Function Model (non-linear)

When the data points are not linearly separable, we can try this method. It apply a basis (non-linear) function (gaussian/polynomial) (feature extractor) to the inputs before pass to the linear model.

### Kernel Method (non-linear)

Another way is to create/change a new/existing feature using a **kernel**, kernel is basically a non-linear function (linear/gaussian/polynomial/hyperbolic tangent).

## Approach II

Binary classification: ***use logistic sigmoid function*** to convert real number to probabilities.

Multi-class classification: ***use softmax*** to convert outputs to probabilities.

**Note** that softmax and logistic sigmoid are essentially the same --- get ratio after applying `exp()` to each output, when number of outputs is > 2, logistic sigmoid is renamed to softmax.

For regression we assume the output of the model follows the gaussian distribution, this is same as adding a gaussian noise with $0$ mean and $\sigma^2$ variance. During training we find the optimal $\sigma^2$ and $w$, if we assume they are deterministic then we get a ordinal least square solution else if we assume they are random then we get a Gaussian Bayesian linear regression model.

## Approach III

Assume independent features and apply Bayes Theorem we get a naive bayes classifier. if we further assume sample in each class follows multivariate gaussian distribution, then we only need to decide a diagonal covariance matrices which is much simpler naive bayes classifier.

Note that since we assume gaussian distribution, the $\mu$ we use will be important because according to the nature of gaussian distribution, values around $\mu$ will get high probability.

# Loss Function

- Sum of Squares Error  --> reduce accumulated error --> linear least square model

we can add regularisation term to prevent overfitting but if it is too large then result in underfitting.

$$O(\theta) = \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{d}{(\hat{y}_{ij} - y_{ij})^2}} + \frac{\lambda}{2}w^Tw$$.

- Mean Squared Error --> average error --> often for neural network

$$O(\theta) = \frac{1}{n}\sum_{i=1}^{n}{(\hat{y}_{i} - y_{i})^2} + \frac{\lambda}{2}w^Tw$$

- Hinge Loss --> models classification

$$O(\theta) = \sum_{i=1}^{n}{max(0, 1 - y_{i}f(\theta, x_i))}$$

same sign --> correct prediction --> if enough margin $0$ else $f(\theta,x_i)$

different sign --> incorrect prediction --> $f(\theta,x_i)$

hinge loss + regularisation = support vector machine (SVM)

$$\underset{(\bold{w}, w_0) \in \Re^{d+1}}{min} = C \sum_{i=1}^{n}{max(0, 1 - y_{i}f(\theta, x_i))} + \frac{1}{2}\bold{w}^T\bold{w}$$.

 $C$ and $\frac{1}{2}\bold{w}^T\bold{w}$ are both regularisation term and $C$ is a hyperparameter.

- Cross Entropy Loss

$$H(p,q) = -\underset{x}{\sum}{p(x)\log(q(x))}$$, where $x$ is the class.

<img src="https://i.ibb.co/pjRwsKR/screenshot-online-manchester-ac-uk-2020-01-18-15-35-02.png" alt="cnl-image" style="zoom:80%;" />

Linear model train with cross entropy loss result in logistic regression.

- (Log) Likelihood

  $\text{likelihood}(\theta|x) = p(x|\theta)$

  We can try to maximize the likelihood of observed data given the set of parameters.

  Maximum Likelihood Estimator (MLE): $\underset{\theta}{max}\ p(x|\theta)$.

  Often, it is convenient to use log likelihood instead: $\underset{\theta}{max}\ \log_b(p(x|\theta))$.

# Optimisation

## Normal Equation

So far in machine learning we are given some inputs $X$ and output $y$. We are trying to solve for some weights $w$ like this:

$\begin{align}Xw&=y\\w&=X^{-1}y\end{align}$

Here the optimal $w$ can be calculated directly by $X^{-1}y$, but $X^{-1}$ only guaranteed to exist when $X$ is a square matrix. So we turn $X$ to $X^TX$ first so that it is guaranteed to be a square matrix.

$\begin{align}X^TXw&=X^Ty\\w&=(X^TX)^{-1}X^Ty\end{align}$

This is called **normal equation**, we also write $(X^TX)^{-1}X^T$ as $X^+$ and call it **Moore-Penrose pseudo-inverse**, our equation now becomes $w=X^+y$. In machine learning we also would like to add a regularisation term $\lambda I$ to the input $X$ to prevent overfitting, where $\lambda$ is a hyper parameter and $I$ is the identity matrix with size of $X$, this gives:

$$w=(X^TX + \lambda I)^{-1}X^Ty$$.

But this is not the end, this indeed solves for optimal $w$ but for many real-life problems the equation is impossible to solve (possibly because input is too huge and huge inverse is too hard to compute). So we use other methods such as gradient descent.

## Gradient Descent

In the normal equation, we are trying to solve the equation by setting $output$ to $0$

$$(X^TX + \lambda I)^{-1}X^Ty - w = output$$.

This is hard, but can we start from random and slowly tune value of $w$ so that the $output$ gets closer and closer to $0$? In order to do this we need to find a way to get a better $w$ given the previous $w$. Derivative is what we are looking for.

> #### According to the definition of the derivative, gradient of a function indicates the direction in which the function ascends the fastest. 

Note that this derivative gives the direction that ***ascend*** the fastest, we have to go the opposite direction so that it ***descent*** the fastest because if the derivative is $0$ then we found a solution where $output$ is $0$ (possibly local optimal not global).

$\theta_{t+1} = \theta - \eta\nabla O(\theta)$

$O(\theta)$ is the result of the loss function, $\nabla$ gives derivative, $\eta$ is the learning rate and $\theta$ is optimizable parameters $w$.

<img src="https://i.ibb.co/KjjFZbk/screenshot-online-manchester-ac-uk-2020-01-18-18-03-31.png" alt="gd-image" style="zoom:80%;" />

# Artificial Neural Network

An neuron is like a simple linear model: $wx+b=y$, this is a simple neuron network --- one layer, one neuron. We can add more neuron to the layer: $w_1x_1+w_2x_2+\dots+w_kx_k+b=y$, this gives a more powerful network --- one layers, multiple neurons. We can also add more layers to form a more powerful network to approximate more complex model.

### Multilayer Perceptron (MLP)

A multilayer perceptron make up of at least 3 layers: input, hidden and output layer. (you can add more hidden layer to get a more powerful MLP). From the input to the second last layer, we can view it as a ***non-linear mapping function*** that generate new and better features for the last ***prediction layer*** to do prediction.

The neuron network can be view as a powerful feature extractor to form an effective representation for the sample.

### Perceptron Algorithm

It is a update rule for binary classification.

$w_{t+1} = w_t + \eta y_ix_i$.

### Backpropagation

It is a technique to calculate gradient of the loss function respect to weights of the network layers.

### Loss Function

- Sum-of-Squared-Error --- summing the errors from batch of samples.
- Cross Entropy Loss --- plugin a sigmoid function into the prediction layer.

### Regularisation

Just add a regularisation term to the loss function

$$O(W_{nn}) = loss(W_{nn}) + \frac{\lambda}{2}||W_{nn}||_2^2$$, where $\lambda$ is a hyper parameter.

#### Chain Rule

$f(g(x)) \rightarrow \frac{df}{dx} = \frac{df}{dg} \times \frac{dg}{dx}$.

## Activations

- Identity
- Sigmoid (0~1)
- Threshold
- ReLU
- Tanh (-1~2)

# Support Vector Machine (SVM)

The main of the SVM is to find the optimal hyperplane that separate the data point with the widest margin.

Margin Width is calculated by $\frac{1}{||w||_2}$.

- Separable --- hard-margin
- Non-separable --- soft-margin (allow data point to stay in margin, when $\xi$ is greater than offset, wrong classification is allowed)

We can use kernel SVM to create non-linear separation.

![kernel-svm-image](https://i.ibb.co/jW5Mv0L/screenshot-online-manchester-ac-uk-2020-01-19-10-22-54.png)

# Notes

### No Free Lunch Theorem

There is no problem-independent reason to favour one method over another. It is task/data dependent.

### KNN

#### Pros

- Easy to learn and implement even for multi-class classification
- No training needed
- Can be use for linear/non-linear
- Only little things to decide --- distance measure and K

#### Cons

- Not memory/time efficient
- Sensitive to outliner
- Does not deal well with imbalance data

### ANN

#### Pros

- Generalize well
- Can solve for complex task
- Learned information is stored in weights
- Do not pose assumption/restrictions to input
- Good choice for black box modelling

#### Cons

- Hard to interpret trained model
- Require large data and long time to train
- Solution maybe a local optimal
- Can be hard to determine a good network architecture

### (Regularized) Linear Least Square

#### Pros

- Works well for small amount of data
- No hyperparameter except regularization term and regularization parameter
- low computation/memory cost
- can be use for classification or regression

#### Cons

- Does not work with non-linear data
- Sensitive to outliner
- Does not offer probabilistic interpolation

### Logistic Regression

### Pros

- Offer nice probabilistic interpolation
- Simple and effective
- low computation/memory cost
- Does not assume specific distribution
- No hyperparameter

#### Cons

- Does not work with non-linear data
- It is for classification only and does not work well with multi-class classification

### SVM

#### Pros

- Provides competitive performance
- Good when no idea what the data is
- Generalize well and solve for a global optimal
- Scale well to higher dimension
- Can handle both linear and non-linear data

#### Cons

- Need to choose a good kernel
- Require long time for training
- Difficult to interpret trained model

# Clustering

- distance measure
- cluster number

## K-mean

predetermine a cluster number n and randomly initialize them.

loop 1) calculate distance between data point and cluster centre. 2) assign each data point to the nearest cluster centre. 3) calculate new data centre 4) stop if there is no change of data point for each centre.

Its complexity is $\mathcal{O}(KTN)$ where $K$ is the number of cluster, $T$ is the number of iterations and $N$ is the number of data points.

#### Cons

- need to specify number of cluster
- cannot handle complex data pattern
- cannot handle noisy data and outliner.

### Cluster Link Measurement

- Complete link measurement: longest distance between two clusters
- First link measurement: shortest distance between two clusters
- Average link measurement: average distance between two clusters.

## Hierarchical

- Agglomerate
- Divisive

initialize by setting all data points as their own cluster, then merge two nearest clusters each iterations.

steps:

1. set all data points as a cluster
2. loop
   1. update distance matrix
   2. merge two closest clusters

#### Cons

- sensitive to outliners
- less efficient $\mathcal{O}(n^2\log n)$

## Internal Index

Normally, a good clustering result will have a small within cluster variance and big between cluster variance.

- $\text{F-ratio index} = K\frac{SSW}{SSB}$, where $SSW$ is within cluster variance and $SSB$ is between cluster variance.

## External Index

- Rand Index: calculate $\frac{\#agreements}{all}$.



